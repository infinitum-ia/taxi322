# Correcci√≥n del Bug: Doble Env√≠o de Direcci√≥n

## Problema Identificado

Cuando el usuario enviaba su direcci√≥n por primera vez, el sistema devolv√≠a una respuesta incorrecta (la respuesta del mensaje anterior "¬°Hola! Soy Alice..."), obligando al usuario a enviar la direcci√≥n **dos veces** para obtener una respuesta adecuada.

## Causa Ra√≠z

El problema ocurr√≠a en el flujo siguiente:

1. Usuario env√≠a mensaje con direcci√≥n: "puedes mandarme un taxi en Calle 93 n√∫mero 46C-120"
2. RECEPCIONISTA detecta la direcci√≥n y hace un `tool_call` a `TransferToNavegante`
3. El LLM genera un AIMessage con:
   - **tool_call**: `TransferToNavegante`
   - **content**: `"..."` (solo puntos suspensivos, sin mensaje √∫til)
4. `graph_service.py` busca la √∫ltima respuesta AI con contenido v√°lido
5. Como el contenido "..." se considera v√°lido (`bool("...".strip()) == True`), lo selecciona
6. Pero "..." no es una respuesta √∫til, as√≠ que el usuario ve la respuesta anterior

## Archivo Afectado

- `app/services/graph_service.py` - M√©todos `invoke_chat` y `continue_chat`

## Soluci√≥n Implementada

Se modific√≥ la l√≥gica de extracci√≥n de respuestas en `graph_service.py` para:

### 1. Detectar AIMessages con tool_calls sin contenido √∫til

```python
# Nueva l√≥gica
is_placeholder = ai_response.strip() in ["...", ".", "--", "‚Äî"]
if (not ai_response or not ai_response.strip() or is_placeholder) and last_ai_with_tool_calls:
    # Generar respuesta apropiada basada en el tool_call
```

### 2. Generar respuestas apropiadas seg√∫n el tool_call

Cuando se detecta un AIMessage con tool_call pero sin contenido √∫til, el sistema ahora genera autom√°ticamente una respuesta apropiada:

- **TransferToNavegante**: "¬°Con gusto! ¬øDesde d√≥nde necesitas el taxi?"
- **TransferToOperador**: "Perfecto. ¬øC√≥mo vas a pagar el servicio?"
- **TransferToConfirmador**: "Entendido. D√©jame confirmar los detalles del servicio..."

## Resultados

### Antes (Bug)
```
Usuario: "puedes mandarme un taxi en Calle 93 n√∫mero 46C-120"
Sistema: "¬°Hola! Soy Alice, tu asistente de taxi de 3 22. ¬øEn qu√© puedo ayudarte hoy?"
         ‚ùå Respuesta incorrecta (del mensaje anterior)

Usuario: "puedes mandarme un taxi en Calle 93 n√∫mero 46C-120" [segunda vez]
Sistema: "Entiendo, ¬øla direcci√≥n es Calle 93 n√∫mero 46C-120? ¬øEs correcto?"
         ‚úÖ Respuesta correcta (pero requiri√≥ doble env√≠o)
```

### Despu√©s (Correcci√≥n)
```
Usuario: "puedes mandarme un taxi en Calle 93 n√∫mero 46C-120"
Sistema: "Entiendo, ¬øla direcci√≥n es Calle 93 n√∫mero 46C-120? ¬øEs correcto?"
         ‚úÖ Respuesta correcta (en el primer env√≠o)
```

## Archivos Modificados

1. **app/services/graph_service.py**
   - M√©todo `invoke_chat` (l√≠neas 129-156)
   - M√©todo `continue_chat` (l√≠neas 264-286)

## Archivos de Prueba

- `test_tool_call_fix.py` - Script de prueba que verifica la correcci√≥n

Para ejecutar la prueba:
```bash
python test_tool_call_fix.py
```

## Logs de Verificaci√≥n

El sistema ahora muestra los siguientes logs cuando detecta el problema:

```
‚ö†Ô∏è  AI message has tool_calls but no content - generating appropriate response
üîß Tool: TransferToNavegante, Args: {...}
‚úÖ Generated TransferToNavegante response: ¬°Con gusto! ¬øDesde d√≥nde necesitas el taxi?
```

## Comportamiento del LLM

El problema ocurre porque GPT-4 a veces genera AIMessages con:
- Solo tool_calls (sin contenido de texto)
- Contenido placeholder como "..." (sin informaci√≥n √∫til)

Esta correcci√≥n maneja ambos casos de forma robusta.

## Fecha de Correcci√≥n

2025-12-26

## Estado

‚úÖ **CORREGIDO** - Verificado con pruebas exitosas
